{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dacd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 23:11:26.117060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 23:11:27.367732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nmalekgh/deep_traffic_git/tes_env_automlprod/venv/lib/\n",
      "2023-03-08 23:11:27.367832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nmalekgh/deep_traffic_git/tes_env_automlprod/venv/lib/\n",
      "2023-03-08 23:11:27.367840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 23:11:29.402633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 23:11:30.092765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 38402 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "if tensorflow.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d86c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmalekgh/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import automl4etc_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5809e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl4etc = automl4etc_common.automl4etc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c35b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl4etc.set_searcher(\"RS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b657712e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of flows with at least 1 packet:  27612\n",
      "AudioStreaming: 2918\n",
      "FileSharing: 1104\n",
      "Gaming: 3334\n",
      "InfoSites: 6793\n",
      "MarketPlace: 3462\n",
      "Messaging: 2010\n",
      "SearchEngine: 3816\n",
      "Social: 2130\n",
      "VideoStreaming: 2045\n",
      "Transforming data for AudioStreaming\n",
      "0 out of 2918\n",
      "100 out of 2918\n",
      "200 out of 2918\n",
      "300 out of 2918\n",
      "400 out of 2918\n",
      "500 out of 2918\n",
      "600 out of 2918\n",
      "700 out of 2918\n",
      "800 out of 2918\n",
      "900 out of 2918\n",
      "1000 out of 2918\n",
      "1100 out of 2918\n",
      "1200 out of 2918\n",
      "1300 out of 2918\n",
      "1400 out of 2918\n",
      "1500 out of 2918\n",
      "1600 out of 2918\n",
      "1700 out of 2918\n",
      "1800 out of 2918\n",
      "1900 out of 2918\n",
      "2000 out of 2918\n",
      "2100 out of 2918\n",
      "2200 out of 2918\n",
      "2300 out of 2918\n",
      "2400 out of 2918\n",
      "2500 out of 2918\n",
      "2600 out of 2918\n",
      "2700 out of 2918\n",
      "2800 out of 2918\n",
      "2900 out of 2918\n",
      "Transforming data for FileSharing\n",
      "0 out of 1104\n",
      "100 out of 1104\n",
      "200 out of 1104\n",
      "300 out of 1104\n",
      "400 out of 1104\n",
      "500 out of 1104\n",
      "600 out of 1104\n",
      "700 out of 1104\n",
      "800 out of 1104\n",
      "900 out of 1104\n",
      "1000 out of 1104\n",
      "1100 out of 1104\n",
      "Transforming data for Gaming\n",
      "0 out of 3334\n",
      "100 out of 3334\n",
      "200 out of 3334\n",
      "300 out of 3334\n",
      "400 out of 3334\n",
      "500 out of 3334\n",
      "600 out of 3334\n",
      "700 out of 3334\n",
      "800 out of 3334\n",
      "900 out of 3334\n",
      "1000 out of 3334\n",
      "1100 out of 3334\n",
      "1200 out of 3334\n",
      "1300 out of 3334\n",
      "1400 out of 3334\n",
      "1500 out of 3334\n",
      "1600 out of 3334\n",
      "1700 out of 3334\n",
      "1800 out of 3334\n",
      "1900 out of 3334\n",
      "2000 out of 3334\n",
      "2100 out of 3334\n",
      "2200 out of 3334\n",
      "2300 out of 3334\n",
      "2400 out of 3334\n",
      "2500 out of 3334\n",
      "2600 out of 3334\n",
      "2700 out of 3334\n",
      "2800 out of 3334\n",
      "2900 out of 3334\n",
      "3000 out of 3334\n",
      "3100 out of 3334\n",
      "3200 out of 3334\n",
      "3300 out of 3334\n",
      "Transforming data for InfoSites\n",
      "0 out of 6793\n",
      "100 out of 6793\n",
      "200 out of 6793\n",
      "300 out of 6793\n",
      "400 out of 6793\n",
      "500 out of 6793\n",
      "600 out of 6793\n",
      "700 out of 6793\n",
      "800 out of 6793\n",
      "900 out of 6793\n",
      "1000 out of 6793\n",
      "1100 out of 6793\n",
      "1200 out of 6793\n",
      "1300 out of 6793\n",
      "1400 out of 6793\n",
      "1500 out of 6793\n",
      "1600 out of 6793\n",
      "1700 out of 6793\n",
      "1800 out of 6793\n",
      "1900 out of 6793\n",
      "2000 out of 6793\n",
      "2100 out of 6793\n",
      "2200 out of 6793\n",
      "2300 out of 6793\n",
      "2400 out of 6793\n",
      "2500 out of 6793\n",
      "2600 out of 6793\n",
      "2700 out of 6793\n",
      "2800 out of 6793\n",
      "2900 out of 6793\n",
      "3000 out of 6793\n",
      "3100 out of 6793\n",
      "3200 out of 6793\n",
      "3300 out of 6793\n",
      "3400 out of 6793\n",
      "3500 out of 6793\n",
      "3600 out of 6793\n",
      "3700 out of 6793\n",
      "3800 out of 6793\n",
      "3900 out of 6793\n",
      "4000 out of 6793\n",
      "4100 out of 6793\n",
      "4200 out of 6793\n",
      "4300 out of 6793\n",
      "4400 out of 6793\n",
      "4500 out of 6793\n",
      "4600 out of 6793\n",
      "4700 out of 6793\n",
      "4800 out of 6793\n",
      "4900 out of 6793\n",
      "5000 out of 6793\n",
      "5100 out of 6793\n",
      "5200 out of 6793\n",
      "5300 out of 6793\n",
      "5400 out of 6793\n",
      "5500 out of 6793\n",
      "5600 out of 6793\n",
      "5700 out of 6793\n",
      "5800 out of 6793\n",
      "5900 out of 6793\n",
      "6000 out of 6793\n",
      "6100 out of 6793\n",
      "6200 out of 6793\n",
      "6300 out of 6793\n",
      "6400 out of 6793\n",
      "6500 out of 6793\n",
      "6600 out of 6793\n",
      "6700 out of 6793\n",
      "Transforming data for MarketPlace\n",
      "0 out of 3462\n",
      "100 out of 3462\n",
      "200 out of 3462\n",
      "300 out of 3462\n",
      "400 out of 3462\n",
      "500 out of 3462\n",
      "600 out of 3462\n",
      "700 out of 3462\n",
      "800 out of 3462\n",
      "900 out of 3462\n",
      "1000 out of 3462\n",
      "1100 out of 3462\n",
      "1200 out of 3462\n",
      "1300 out of 3462\n",
      "1400 out of 3462\n",
      "1500 out of 3462\n",
      "1600 out of 3462\n",
      "1700 out of 3462\n",
      "1800 out of 3462\n",
      "1900 out of 3462\n",
      "2000 out of 3462\n",
      "2100 out of 3462\n",
      "2200 out of 3462\n",
      "2300 out of 3462\n",
      "2400 out of 3462\n",
      "2500 out of 3462\n",
      "2600 out of 3462\n",
      "2700 out of 3462\n",
      "2800 out of 3462\n",
      "2900 out of 3462\n",
      "3000 out of 3462\n",
      "3100 out of 3462\n",
      "3200 out of 3462\n",
      "3300 out of 3462\n",
      "3400 out of 3462\n",
      "Transforming data for Messaging\n",
      "0 out of 2010\n",
      "100 out of 2010\n",
      "200 out of 2010\n",
      "300 out of 2010\n",
      "400 out of 2010\n",
      "500 out of 2010\n",
      "600 out of 2010\n",
      "700 out of 2010\n",
      "800 out of 2010\n",
      "900 out of 2010\n",
      "1000 out of 2010\n",
      "1100 out of 2010\n",
      "1200 out of 2010\n",
      "1300 out of 2010\n",
      "1400 out of 2010\n",
      "1500 out of 2010\n",
      "1600 out of 2010\n",
      "1700 out of 2010\n",
      "1800 out of 2010\n",
      "1900 out of 2010\n",
      "2000 out of 2010\n",
      "Transforming data for SearchEngine\n",
      "0 out of 3816\n",
      "100 out of 3816\n",
      "200 out of 3816\n",
      "300 out of 3816\n",
      "400 out of 3816\n",
      "500 out of 3816\n",
      "600 out of 3816\n",
      "700 out of 3816\n",
      "800 out of 3816\n",
      "900 out of 3816\n",
      "1000 out of 3816\n",
      "1100 out of 3816\n",
      "1200 out of 3816\n",
      "1300 out of 3816\n",
      "1400 out of 3816\n",
      "1500 out of 3816\n",
      "1600 out of 3816\n",
      "1700 out of 3816\n",
      "1800 out of 3816\n",
      "1900 out of 3816\n",
      "2000 out of 3816\n",
      "2100 out of 3816\n",
      "2200 out of 3816\n",
      "2300 out of 3816\n",
      "2400 out of 3816\n",
      "2500 out of 3816\n",
      "2600 out of 3816\n",
      "2700 out of 3816\n",
      "2800 out of 3816\n",
      "2900 out of 3816\n",
      "3000 out of 3816\n",
      "3100 out of 3816\n",
      "3200 out of 3816\n",
      "3300 out of 3816\n",
      "3400 out of 3816\n",
      "3500 out of 3816\n",
      "3600 out of 3816\n",
      "3700 out of 3816\n",
      "3800 out of 3816\n",
      "Transforming data for Social\n",
      "0 out of 2130\n",
      "100 out of 2130\n",
      "200 out of 2130\n",
      "300 out of 2130\n",
      "400 out of 2130\n",
      "500 out of 2130\n",
      "600 out of 2130\n",
      "700 out of 2130\n",
      "800 out of 2130\n",
      "900 out of 2130\n",
      "1000 out of 2130\n",
      "1100 out of 2130\n",
      "1200 out of 2130\n",
      "1300 out of 2130\n",
      "1400 out of 2130\n",
      "1500 out of 2130\n",
      "1600 out of 2130\n",
      "1700 out of 2130\n",
      "1800 out of 2130\n",
      "1900 out of 2130\n",
      "2000 out of 2130\n",
      "2100 out of 2130\n",
      "Transforming data for VideoStreaming\n",
      "0 out of 2045\n",
      "100 out of 2045\n",
      "200 out of 2045\n",
      "300 out of 2045\n",
      "400 out of 2045\n",
      "500 out of 2045\n",
      "600 out of 2045\n",
      "700 out of 2045\n",
      "800 out of 2045\n",
      "900 out of 2045\n",
      "1000 out of 2045\n",
      "1100 out of 2045\n",
      "1200 out of 2045\n",
      "1300 out of 2045\n",
      "1400 out of 2045\n",
      "1500 out of 2045\n",
      "1600 out of 2045\n",
      "1700 out of 2045\n",
      "1800 out of 2045\n",
      "1900 out of 2045\n",
      "2000 out of 2045\n",
      "(27612, 3, 600)\n",
      "(27612,)\n",
      "[('AudioStreaming', 2334), ('FileSharing', 883), ('Gaming', 2667), ('InfoSites', 5434), ('MarketPlace', 2770), ('Messaging', 1608), ('SearchEngine', 3053), ('Social', 1704), ('VideoStreaming', 1636)]\n",
      "{'MarketPlace': 2770, 'Messaging': 1608, 'InfoSites': 5434, 'AudioStreaming': 2334, 'SearchEngine': 3053, 'FileSharing': 883, 'Gaming': 2667, 'VideoStreaming': 1636, 'Social': 1704}\n",
      "[('AudioStreaming', 584), ('FileSharing', 221), ('Gaming', 667), ('InfoSites', 1359), ('MarketPlace', 692), ('Messaging', 402), ('SearchEngine', 763), ('Social', 426), ('VideoStreaming', 409)]\n",
      "{'Gaming': 667, 'InfoSites': 1359, 'SearchEngine': 763, 'FileSharing': 221, 'Messaging': 402, 'Social': 426, 'AudioStreaming': 584, 'MarketPlace': 692, 'VideoStreaming': 409}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 23:12:00.801821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38402 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "train, test = automl4etc.mldit_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef7ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-08 23:12:04 I hypernets.c.meta_learner.py 22 - Initialize Meta Learner: dataset_id:35db9d1c6a07383da4a5dbd4499b4a19\n",
      "03-08 23:12:04 I hypernets.c.callbacks.py 235 - \n",
      "Trial No:1\n",
      "--------------------------------------------------------------\n",
      "(0) Module_InputChoice_1.hp_choice:                       [1]\n",
      "(1) Module_InputChoice_2.hp_choice:                       [1]\n",
      "(2) Module_ModuleChoice_1.hp_or:                            1\n",
      "(3) Module_ModuleChoice_2.hp_or:                            3\n",
      "(4) Module_InputChoice_3.hp_choice:                       [1]\n",
      "(5) Module_InputChoice_4.hp_choice:                       [1]\n",
      "(6) Module_ModuleChoice_3.hp_or:                            0\n",
      "(7) Module_ModuleChoice_4.hp_or:                            2\n",
      "(8) Module_InputChoice_5.hp_choice:                       [2]\n",
      "(9) Module_InputChoice_6.hp_choice:                       [3]\n",
      "(10) Module_ModuleChoice_5.hp_or:                           0\n",
      "(11) Module_ModuleChoice_6.hp_or:                           0\n",
      "(12) Module_InputChoice_7.hp_choice:                      [1]\n",
      "(13) Module_InputChoice_8.hp_choice:                      [1]\n",
      "(14) Module_ModuleChoice_7.hp_or:                           1\n",
      "(15) Module_ModuleChoice_8.hp_or:                           3\n",
      "(16) Module_InputChoice_10.hp_choice:                     [1]\n",
      "(17) Module_InputChoice_9.hp_choice:                      [0]\n",
      "(18) Module_ModuleChoice_10.hp_or:                          4\n",
      "(19) Module_ModuleChoice_9.hp_or:                           4\n",
      "(20) Module_InputChoice_11.hp_choice:                     [2]\n",
      "(21) Module_InputChoice_12.hp_choice:                     [2]\n",
      "(22) Module_ModuleChoice_11.hp_or:                          4\n",
      "(23) Module_ModuleChoice_12.hp_or:                          4\n",
      "(24) Module_InputChoice_13.hp_choice:                     [2]\n",
      "(25) Module_InputChoice_14.hp_choice:                     [0]\n",
      "(26) Module_ModuleChoice_13.hp_or:                          4\n",
      "(27) Module_ModuleChoice_14.hp_or:                          0\n",
      "(28) Module_InputChoice_15.hp_choice:                     [3]\n",
      "(29) Module_InputChoice_16.hp_choice:                     [0]\n",
      "(30) Module_ModuleChoice_15.hp_or:                          2\n",
      "(31) Module_ModuleChoice_16.hp_or:                          4\n",
      "--------------------------------------------------------------\n",
      "trial 1 begin\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " 0_input (InputLayer)           [(None, 3, 600)]     0           []                               \n",
      "                                                                                                  \n",
      " 0_input_Flatten (Reshape)      (None, 1800, 1)      0           ['0_input[0][0]']                \n",
      "                                                                                                  \n",
      " 0_stem_conv1d (Conv1D)         (None, 1800, 192)    768         ['0_input_Flatten[0][0]']        \n",
      "                                                                                                  \n",
      " 0_stem_bn (BatchNormalization)  (None, 1800, 192)   768         ['0_stem_conv1d[0][0]']          \n",
      "                                                                                                  \n",
      " 1_normal_C1_input0_filter_alig  (None, 1800, 64)    12608       ['0_stem_bn[0][0]']              \n",
      " nment (FilterAlignment)                                                                          \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_re  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n",
      " lu_0_ (Activation)                                              ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n",
      " lu_0_ (Activation)                                              ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_se  (None, 1800, 64)    4352        ['1_normal_C1_N0_L_sepconv3x3_rel\n",
      " pconv1d_0 (SeparableConv1D)                                     u_0_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N1_L_sepconv5x5_rel\n",
      " pconv1d_0 (SeparableConv1D)                                     u_0_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_bn  (None, 1800, 64)    256         ['1_normal_C1_N0_L_sepconv3x3_sep\n",
      " _0_ (BatchNormalization)                                        conv1d_0[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N1_L_sepconv5x5_sep\n",
      " _0_ (BatchNormalization)                                        conv1d_0[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_bn  (None, 1800, 64)    0           ['1_normal_C1_N0_L_sepconv3x3_bn_\n",
      " _dropout_0_ (Dropout)                                           0_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N1_L_sepconv5x5_bn_\n",
      " _dropout_0_ (Dropout)                                           0_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_re  (None, 1800, 64)    0           ['1_normal_C1_N0_L_sepconv3x3_bn_\n",
      " lu_1_ (Activation)                                              dropout_0_[0][0]']               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_N1_L_sepconv5x5_bn_\n",
      " lu_1_ (Activation)                                              dropout_0_[0][0]']               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_se  (None, 1800, 64)    4352        ['1_normal_C1_N0_L_sepconv3x3_rel\n",
      " pconv1d_1 (SeparableConv1D)                                     u_1_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N1_L_sepconv5x5_rel\n",
      " pconv1d_1 (SeparableConv1D)                                     u_1_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_bn  (None, 1800, 64)    256         ['1_normal_C1_N0_L_sepconv3x3_sep\n",
      " _1_ (BatchNormalization)                                        conv1d_1[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N1_L_sepconv5x5_sep\n",
      " _1_ (BatchNormalization)                                        conv1d_1[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_L_sepconv3x3_bn  (None, 1800, 64)    0           ['1_normal_C1_N0_L_sepconv3x3_bn_\n",
      " _dropout_1_ (Dropout)                                           1_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_R_maxpooling3x3  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _pool_ (MaxPooling1D)                                           ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_L_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N1_L_sepconv5x5_bn_\n",
      " _dropout_1_ (Dropout)                                           1_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_R_avgpooling3x3  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n",
      " _pool_ (AveragePooling1D)                                       ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N0_add_ (Add)      (None, 1800, 64)     0           ['1_normal_C1_N0_L_sepconv3x3_bn_\n",
      "                                                                 dropout_1_[0][0]',               \n",
      "                                                                  '1_normal_C1_N0_R_maxpooling3x3_\n",
      "                                                                 pool_[0][0]']                    \n",
      "                                                                                                  \n",
      " 1_normal_C1_N1_add_ (Add)      (None, 1800, 64)     0           ['1_normal_C1_N1_L_sepconv5x5_bn_\n",
      "                                                                 dropout_1_[0][0]',               \n",
      "                                                                  '1_normal_C1_N1_R_avgpooling3x3_\n",
      "                                                                 pool_[0][0]']                    \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_N0_add_[0][0]']    \n",
      " lu_0_ (Activation)                                                                               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_N1_add_[0][0]']    \n",
      " lu_0_ (Activation)                                                                               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_re  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n",
      " lu_0_ (Activation)                                              ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N2_L_sepconv5x5_rel\n",
      " pconv1d_0 (SeparableConv1D)                                     u_0_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N2_R_sepconv5x5_rel\n",
      " pconv1d_0 (SeparableConv1D)                                     u_0_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_se  (None, 1800, 64)    4352        ['1_normal_C1_N3_L_sepconv3x3_rel\n",
      " pconv1d_0 (SeparableConv1D)                                     u_0_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N2_L_sepconv5x5_sep\n",
      " _0_ (BatchNormalization)                                        conv1d_0[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N2_R_sepconv5x5_sep\n",
      " _0_ (BatchNormalization)                                        conv1d_0[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_bn  (None, 1800, 64)    256         ['1_normal_C1_N3_L_sepconv3x3_sep\n",
      " _0_ (BatchNormalization)                                        conv1d_0[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N2_L_sepconv5x5_bn_\n",
      " _dropout_0_ (Dropout)                                           0_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N2_R_sepconv5x5_bn_\n",
      " _dropout_0_ (Dropout)                                           0_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_bn  (None, 1800, 64)    0           ['1_normal_C1_N3_L_sepconv3x3_bn_\n",
      " _dropout_0_ (Dropout)                                           0_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_N2_L_sepconv5x5_bn_\n",
      " lu_1_ (Activation)                                              dropout_0_[0][0]']               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_re  (None, 1800, 64)    0           ['1_normal_C1_N2_R_sepconv5x5_bn_\n",
      " lu_1_ (Activation)                                              dropout_0_[0][0]']               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_re  (None, 1800, 64)    0           ['1_normal_C1_N3_L_sepconv3x3_bn_\n",
      " lu_1_ (Activation)                                              dropout_0_[0][0]']               \n",
      "                                                                                                  \n",
      " 2_reduction_C1_0reduction_ (Fa  (None, 900, 128)    12864       ['0_stem_bn[0][0]']              \n",
      " ctorizedReduction_K)                                                                             \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N2_L_sepconv5x5_rel\n",
      " pconv1d_1 (SeparableConv1D)                                     u_1_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_se  (None, 1800, 64)    4480        ['1_normal_C1_N2_R_sepconv5x5_rel\n",
      " pconv1d_1 (SeparableConv1D)                                     u_1_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_se  (None, 1800, 64)    4352        ['1_normal_C1_N3_L_sepconv3x3_rel\n",
      " pconv1d_1 (SeparableConv1D)                                     u_1_[0][0]']                     \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N2_L_sepconv5x5_sep\n",
      " _1_ (BatchNormalization)                                        conv1d_1[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_bn  (None, 1800, 64)    256         ['1_normal_C1_N2_R_sepconv5x5_sep\n",
      " _1_ (BatchNormalization)                                        conv1d_1[0][0]']                 \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_bn  (None, 1800, 64)    256         ['1_normal_C1_N3_L_sepconv3x3_sep\n",
      " _1_ (BatchNormalization)                                        conv1d_1[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    0           ['2_reduction_C1_0reduction_[0][0\n",
      " _relu_0_ (Activation)                                           ]']                              \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_L_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N2_L_sepconv5x5_bn_\n",
      " _dropout_1_ (Dropout)                                           1_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_R_sepconv5x5_bn  (None, 1800, 64)    0           ['1_normal_C1_N2_R_sepconv5x5_bn_\n",
      " _dropout_1_ (Dropout)                                           1_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_L_sepconv3x3_bn  (None, 1800, 64)    0           ['1_normal_C1_N3_L_sepconv3x3_bn_\n",
      " _dropout_1_ (Dropout)                                           1_[0][0]']                       \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_R_maxpooling3x3  (None, 1800, 64)    0           ['1_normal_C1_input0_filter_align\n",
      " _pool_ (MaxPooling1D)                                           ment[0][0]']                     \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    17152       ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _sepconv1d_0 (SeparableConv1D)                                  relu_0_[0][0]']                  \n",
      "                                                                                                  \n",
      " 1_normal_C1_N2_add_ (Add)      (None, 1800, 64)     0           ['1_normal_C1_N2_L_sepconv5x5_bn_\n",
      "                                                                 dropout_1_[0][0]',               \n",
      "                                                                  '1_normal_C1_N2_R_sepconv5x5_bn_\n",
      "                                                                 dropout_1_[0][0]']               \n",
      "                                                                                                  \n",
      " 1_normal_C1_N3_add_ (Add)      (None, 1800, 64)     0           ['1_normal_C1_N3_L_sepconv3x3_bn_\n",
      "                                                                 dropout_1_[0][0]',               \n",
      "                                                                  '1_normal_C1_N3_R_maxpooling3x3_\n",
      "                                                                 pool_[0][0]']                    \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    512         ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _bn_0_ (BatchNormalization)                                     sepconv1d_0[0][0]']              \n",
      "                                                                                                  \n",
      " 1_normal_C1_add_ (Add)         (None, 1800, 64)     0           ['1_normal_C1_N2_add_[0][0]',    \n",
      "                                                                  '1_normal_C1_N3_add_[0][0]']    \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    0           ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _bn_dropout_0_ (Dropout)                                        bn_0_[0][0]']                    \n",
      "                                                                                                  \n",
      " 2_reduction_C1_1reduction_ (Fa  (None, 900, 128)    4672        ['1_normal_C1_add_[0][0]']       \n",
      " ctorizedReduction_K)                                                                             \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    0           ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _relu_1_ (Activation)                                           bn_dropout_0_[0][0]']            \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N0_add_ (Add)   (None, 900, 128)     0           ['2_reduction_C1_0reduction_[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  '2_reduction_C1_1reduction_[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    17152       ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _sepconv1d_1 (SeparableConv1D)                                  relu_1_[0][0]']                  \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    512         ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _bn_1_ (BatchNormalization)                                     sepconv1d_1[0][0]']              \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N1_add_ (Add)   (None, 900, 128)     0           ['2_reduction_C1_N0_add_[0][0]', \n",
      "                                                                  '2_reduction_C1_N0_add_[0][0]'] \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_R_sepconv5x5  (None, 900, 128)    0           ['2_reduction_C1_N2_R_sepconv5x5_\n",
      " _bn_dropout_1_ (Dropout)                                        bn_1_[0][0]']                    \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N3_L_avgpooling  (None, 900, 128)    0           ['2_reduction_C1_N1_add_[0][0]'] \n",
      " 3x3_pool_ (AveragePooling1D)                                                                     \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N2_add_ (Add)   (None, 900, 128)     0           ['2_reduction_C1_N0_add_[0][0]', \n",
      "                                                                  '2_reduction_C1_N2_R_sepconv5x5_\n",
      "                                                                 bn_dropout_1_[0][0]']            \n",
      "                                                                                                  \n",
      " 2_reduction_C1_N3_add_ (Add)   (None, 900, 128)     0           ['2_reduction_C1_N3_L_avgpooling3\n",
      "                                                                 x3_pool_[0][0]',                 \n",
      "                                                                  '2_reduction_C1_0reduction_[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " 2_reduction_C1_add_ (Add)      (None, 900, 128)     0           ['2_reduction_C1_N2_add_[0][0]', \n",
      "                                                                  '2_reduction_C1_N3_add_[0][0]'] \n",
      "                                                                                                  \n",
      " classification_relu (Activatio  (None, 900, 128)    0           ['2_reduction_C1_add_[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " classification_global_avgpool   (None, 128)         0           ['classification_relu[0][0]']    \n",
      " (GlobalAveragePooling1D)                                                                         \n",
      "                                                                                                  \n",
      " classification_logit (Dense)   (None, 9)            1161        ['classification_global_avgpool[0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 115,017\n",
      "Trainable params: 112,201\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 23:12:12.768820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-08 23:12:13.359933: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-08 23:12:13.361477: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:14.091059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-08 23:12:14.103102: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f35e4006aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-08 23:12:14.103199: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2023-03-08 23:12:14.108489: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-08 23:12:14.185055: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-08 23:12:14.185279: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:14.242185: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-03-08 23:12:14.311948: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:14.477249: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:15.036545: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:15.161121: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:15.295727: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:16.843708: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-03-08 23:12:16.973822: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/173 [..............................] - ETA: 22s - loss: 3.9014 - sparse_categorical_accuracy: 0.1406  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 23:12:20.367454: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 30s 91ms/step - loss: 2.2363 - sparse_categorical_accuracy: 0.2079 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 2/40\n",
      " 90/173 [==============>...............] - ETA: 7s - loss: 2.0981 - sparse_categorical_accuracy: 0.2283"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoml4etc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/automl4etc_common.py:136\u001b[0m, in \u001b[0;36mautoml4etc.search\u001b[0;34m(self, train_dataset, test_dataset, input_shape, classes)\u001b[0m\n\u001b[1;32m    133\u001b[0m y_train1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y_train1)\n\u001b[1;32m    134\u001b[0m y_test1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(y_test1)\n\u001b[0;32m--> 136\u001b[0m \u001b[43mhk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hk\u001b[38;5;241m.\u001b[39mget_best_trial()\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/hypernets/model/hyper_model.py:192\u001b[0m, in \u001b[0;36mHyperModel.search\u001b[0;34m(self, X, y, X_eval, y_eval, cv, num_folds, max_trials, dataset_id, trial_store, **fit_kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_search_start(\u001b[38;5;28mself\u001b[39m, X, y, X_eval, y_eval,\n\u001b[1;32m    189\u001b[0m                              cv, num_folds, max_trials, dataset_id, trial_store,\n\u001b[1;32m    190\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     trial_no \u001b[38;5;241m=\u001b[39m \u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    197\u001b[0m         callback\u001b[38;5;241m.\u001b[39mon_search_end(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/hypernets/dispatchers/in_process_dispatcher.py:60\u001b[0m, in \u001b[0;36mInProcessDispatcher.dispatch\u001b[0;34m(self, hyper_model, X, y, X_eval, y_eval, cv, num_folds, max_trials, dataset_id, trial_store, **fit_kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_trial_begin(hyper_model, space_sample, trial_no)\n\u001b[1;32m     58\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%05d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dir, trial_no, space_sample\u001b[38;5;241m.\u001b[39mspace_id)\n\u001b[0;32m---> 60\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[43mhyper_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trial\u001b[38;5;241m.\u001b[39msucceeded:\n\u001b[1;32m     64\u001b[0m     improved \u001b[38;5;241m=\u001b[39m hyper_model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend(trial)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/hypernets/model/hyper_model.py:65\u001b[0m, in \u001b[0;36mHyperModel._run_trial\u001b[0;34m(self, space_sample, trial_no, X, y, X_eval, y_eval, cv, num_folds, model_file, **fit_kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         scores, oof, oof_scores \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mfit_cross_validation(X, y, stratified\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_folds\u001b[38;5;241m=\u001b[39mnum_folds,\n\u001b[1;32m     61\u001b[0m                                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9527\u001b[39m,\n\u001b[1;32m     62\u001b[0m                                                                  metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_metric],\n\u001b[1;32m     63\u001b[0m                                                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnPromisingTrial \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/hyperkeras/hyper_keras.py:70\u001b[0m, in \u001b[0;36mKerasEstimator.fit\u001b[0;34m(self, X, y, validation_gen, initial_lr, class_weight, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#self.model.fit(X, y, **kwargs)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validation_gen:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLearningRateScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_exp_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X, callbacks\u001b[38;5;241m=\u001b[39m[LearningRateScheduler(lr_exp_decay, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], class_weight\u001b[38;5;241m=\u001b[39mclass_weight, validation_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mvalidation_gen, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/deep_traffic_git/tes_env_automlprod/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "automl4etc.search(train_dataset=train, test_dataset=test, input_shape=(3, 600), classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7da212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv] *",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
